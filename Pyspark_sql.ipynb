{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w_mq6I_r2pD-"
      },
      "outputs": [],
      "source": [
        "import pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n"
      ],
      "metadata": {
        "id": "20MN6eLf2_-r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"MySQL-Connection-Test\").config(\"spark.jars.packages\", \"com.mysql:mysql-connector-j:8.3.0\").getOrCreate()"
      ],
      "metadata": {
        "id": "9QUVZAke4Gmq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jdbc_url = \"jdbc:mysql://mysql-rfam-public.ebi.ac.uk:4497/Rfam\"\n",
        "connection_properties = {\n",
        "    \"user\": \"rfamro\",\n",
        "    \"password\": \"\",\n",
        "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
        "}"
      ],
      "metadata": {
        "id": "6eEs5_tH4UUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark_db = spark.read.jdbc(url=jdbc_url, table=\"family\", properties=connection_properties)\n",
        "\n",
        "    # Show the first 5 rows\n",
        "df_pyspark_db.select(\"rfam_acc\", \"rfam_id\", \"description\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9LEYitY4atx",
        "outputId": "b4d6f29c-ab4a-4d88-d770-e92f770d4f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+-------------------+\n",
            "|rfam_acc|  rfam_id|        description|\n",
            "+--------+---------+-------------------+\n",
            "| RF00001|  5S_rRNA|   5S ribosomal RNA|\n",
            "| RF00002|5_8S_rRNA| 5.8S ribosomal RNA|\n",
            "| RF00003|       U1|U1 spliceosomal RNA|\n",
            "| RF00004|       U2|U2 spliceosomal RNA|\n",
            "| RF00005|     tRNA|               tRNA|\n",
            "+--------+---------+-------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3TxkKMu5bW6",
        "outputId": "a0fbb1c1-47e7-44c7-af3f-bfb4da4ea270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pyspark --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op2ySgmg5e-o",
        "outputId": "53e5b56a-8d14-46d8-db2c-ef66bc9347fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Using incubator modules: jdk.incubator.vector\n",
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /___/ .__/\\_,_/_/ /_/\\_\\   version 4.0.2\n",
            "      /_/\n",
            "                        \n",
            "Using Scala version 2.13.16, OpenJDK 64-Bit Server VM, 17.0.17\n",
            "Branch HEAD\n",
            "Compiled by user runner on 2026-02-02T08:08:13Z\n",
            "Revision 7cc3b9bcdaab8c923f23cdbc9ce922530e1becf1\n",
            "Url https://github.com/apache/spark\n",
            "Type --help for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUXtPauA5kFN",
        "outputId": "3228ef1f-13c6-41c0-d208-eb26ba22b32f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"17.0.17\" 2025-10-21\n",
            "OpenJDK Runtime Environment (build 17.0.17+10-Ubuntu-122.04)\n",
            "OpenJDK 64-Bit Server VM (build 17.0.17+10-Ubuntu-122.04, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "ZH7SEKHs09Ac"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sparkContext.getConf().get(\"spark.jars.packages\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "o9D_yiuR1Bt5",
        "outputId": "6a4bdf80-a0dd-4802-f287-86a57e011bae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'com.mysql:mysql-connector-j:8.3.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''properties = {\n",
        "    \"user\": \"root\",\n",
        "    \"password\": \"root\",\n",
        "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
        "}\n",
        "\n",
        "df = spark.read.jdbc(\n",
        "    url=jdbc_url,\n",
        "    table=\"student\",\n",
        "    properties=properties\n",
        ")\n",
        "\n",
        "df.show()'''\n",
        "#this wont work becasue jars drivers are not installed"
      ],
      "metadata": {
        "id": "Jc92Lat01Lbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sparkContext.getConf().get(\"spark.jars.packages\") #msql connector is loaded properly"
      ],
      "metadata": {
        "id": "nyaL229V1MFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sparkContext._jsc.sc().listJars() # samll verify"
      ],
      "metadata": {
        "id": "Cx9M5uJx1OZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(spark.sparkContext._jsc.sc().listJars())# this as well to verify"
      ],
      "metadata": {
        "id": "6-DLaB0a1QXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jars = list(spark.sparkContext._jsc.sc().listJars())\n",
        "print(jars) #1st intration to know if jars are loded or not"
      ],
      "metadata": {
        "id": "CkuRBh5W1Sa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the Java Vector\n",
        "jars_vector = spark.sparkContext._jsc.sc().listJars()\n",
        "\n",
        "# Convert to Python list\n",
        "jars_list = [str(jars_vector.get(i)) for i in range(jars_vector.size())]\n",
        "\n",
        "print(jars_list) # if the [] jar is not loaded which means drivers for mysql is not installed need to downlaod and install\n",
        "\n",
        "#https://dev.mysql.com/downloads/connector/j/"
      ],
      "metadata": {
        "id": "FxE2ilk81VBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path to your MySQL JAR\n",
        "mysql_jar = \"Projects_DS/pyspark/mysql-connector-j-8.0.33.jar\"\n",
        "\n",
        "# Tell Spark to load the JAR at JVM startup\n",
        "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = f\"--jars {mysql_jar} pyspark-shell\""
      ],
      "metadata": {
        "id": "2aUs4h6A1VwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"MySQLConnection\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "IGo1wSHe1YBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jars_vector = spark.sparkContext._jsc.sc().listJars()\n",
        "jars_list = [str(jars_vector.get(i)) for i in range(jars_vector.size())]\n",
        "print(jars_list)"
      ],
      "metadata": {
        "id": "oPEJ0Ave1XOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ce5Tqwff1ark"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G8pwV3Aq1aOr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}